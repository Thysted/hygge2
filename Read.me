Description

This project involves using language models for text generation and retrieval. The primary focus is on setting up and utilizing TheBloke/Llama-2-7B-Chat-GPTQ, a language model available through HuggingFace's Transformers library.


Setup

The setup process installs necessary dependencies using pip, including LangChain, Transformers, ChromaDB, and other relevant libraries.

Model (LLM) Wrappers

The code initializes the LLM using HuggingFacePipeline, specifying the model name, tokenizer, and generation configuration.

Simple Retrieval Augmented Generation (RAG)

Demonstrates the use of LangChain's data loaders to load documents from external sources, particularly PDF files. The PDFs are merged into a single document for processing.

RetrievalQA Chain

The RetrievalQA chain combines the LLM with a Chroma database for retrieval augmented generation. It uses a prompt template to query the model based on the top results from the database.
